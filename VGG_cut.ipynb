{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.993772029876709\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "input_datafile = h5py.File('../input/uploads/uploads/tryp')\n",
    "\n",
    "train_norm_images = np.array(input_datafile['train_norm'])\n",
    "train_trypo_images = np.array(input_datafile['train_trypo'])\n",
    "valid_norm_images = np.array(input_datafile['valid_norm'])\n",
    "valid_trypo_images = np.array(input_datafile['valid_trypo'])\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.94642857  0.75        0.00446429]\n",
      "  [ 0.94642857  0.75        0.00446429]\n",
      "  [ 0.94642857  0.75        0.00446429]\n",
      "  ..., \n",
      "  [ 0.96428571  0.72767857  0.        ]\n",
      "  [ 0.99107143  0.74107143  0.        ]\n",
      "  [ 0.97321429  0.72321429  0.        ]]\n",
      "\n",
      " [[ 0.94642857  0.75        0.00446429]\n",
      "  [ 0.94642857  0.75        0.00446429]\n",
      "  [ 0.94642857  0.75        0.00446429]\n",
      "  ..., \n",
      "  [ 0.94642857  0.71875     0.00892857]\n",
      "  [ 0.96875     0.72767857  0.00892857]\n",
      "  [ 0.94196429  0.69642857  0.00446429]]\n",
      "\n",
      " [[ 0.94196429  0.74553571  0.        ]\n",
      "  [ 0.94196429  0.74553571  0.        ]\n",
      "  [ 0.94196429  0.74553571  0.        ]\n",
      "  ..., \n",
      "  [ 0.93303571  0.71428571  0.04017857]\n",
      "  [ 0.95535714  0.72767857  0.03571429]\n",
      "  [ 0.92410714  0.69196429  0.00892857]]\n",
      "\n",
      " ..., \n",
      " [[ 0.55803571  0.33928571  0.02678571]\n",
      "  [ 0.55803571  0.33928571  0.02678571]\n",
      "  [ 0.55803571  0.33482143  0.02678571]\n",
      "  ..., \n",
      "  [ 0.84821429  0.60714286  0.        ]\n",
      "  [ 0.84821429  0.60714286  0.        ]\n",
      "  [ 0.84821429  0.61160714  0.        ]]\n",
      "\n",
      " [[ 0.55803571  0.33928571  0.02678571]\n",
      "  [ 0.55803571  0.33928571  0.02678571]\n",
      "  [ 0.55803571  0.33482143  0.02678571]\n",
      "  ..., \n",
      "  [ 0.84821429  0.60714286  0.        ]\n",
      "  [ 0.84821429  0.60714286  0.        ]\n",
      "  [ 0.84821429  0.60714286  0.        ]]\n",
      "\n",
      " [[ 0.55803571  0.34375     0.02232143]\n",
      "  [ 0.5625      0.34375     0.02232143]\n",
      "  [ 0.5625      0.33928571  0.02232143]\n",
      "  ..., \n",
      "  [ 0.84821429  0.59821429  0.        ]\n",
      "  [ 0.85267857  0.60267857  0.        ]\n",
      "  [ 0.85267857  0.60267857  0.        ]]]\n",
      "(15884, 2)\n",
      "(15884, 224, 224, 3)\n",
      "(1000, 2)\n",
      "(1000, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "    \n",
    "def process_images(image):\n",
    "    return np.divide(image, 224)\n",
    "\n",
    "def join_data(norm, trypo):\n",
    "    X = np.concatenate([norm, trypo])\n",
    "    Y1 = np.zeros(len(norm))\n",
    "    Y2 = np.ones(len(trypo))\n",
    "    Y = np.concatenate([Y1, Y2])\n",
    "    Y = np_utils.to_categorical(Y) \n",
    "    print(Y.shape)\n",
    "    print(X.shape)\n",
    "    return X, Y\n",
    "\n",
    "train_norm_images = process_images(train_norm_images)\n",
    "train_trypo_images = process_images(train_trypo_images)\n",
    "valid_norm_images = process_images(valid_norm_images)\n",
    "valid_trypo_images = process_images(valid_trypo_images)\n",
    "\n",
    "print(train_norm_images[0])\n",
    "\n",
    "X, Y = join_data(train_norm_images, train_trypo_images)\n",
    "X_val, Y_val = join_data(valid_norm_images, valid_trypo_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import GlobalAveragePooling2D, Dense\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "model = VGG16(include_top = False, weights='imagenet')\n",
    "\n",
    "def cut_model(n):\n",
    "    x = GlobalAveragePooling2D()(model.layers[-n-1].output)\n",
    "    pred = Dense(2, activation='softmax')(x)\n",
    "    new_model = Model(input = model.input, output = [pred])\n",
    "    for layer in new_model.layers[:-2]:\n",
    "        layer.trainable = False\n",
    "    new_model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\",\n",
    "                 metrics = [\"accuracy\"])\n",
    "    new_model.evaluate(X_val, Y_val)\n",
    "    return new_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/share/jupyter/kernels/neptune-kernel/neptunekernel.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=Tensor(\"in...)`\n",
      "  # Unless required by applicable law or agreed to in writing, software\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 18s    \n",
      "1000/1000 [==============================] - 16s    \n",
      "1000/1000 [==============================] - 12s    \n",
      "1000/1000 [==============================] - 8s     \n",
      "1000/1000 [==============================] - 5s     \n"
     ]
    }
   ],
   "source": [
    "full_model = cut_model(0)\n",
    "first_cut_model = cut_model(4)\n",
    "second_cut_model = cut_model(8)\n",
    "third_cut_model = cut_model(12)\n",
    "last_cut_model = cut_model(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15884 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "15884/15884 [==============================] - 298s - loss: 0.3665 - acc: 0.8454 - val_loss: 0.2912 - val_acc: 0.8860\n",
      "Epoch 2/10\n",
      "12096/15884 [=====================>........] - ETA: 66s - loss: 0.2792 - acc: 0.8903"
     ]
    }
   ],
   "source": [
    "full_model_hist = full_model.fit(X, Y, epochs = 10, validation_data=[X_val, Y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(full_model_hist.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Neptune",
   "language": "",
   "name": "neptune-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
